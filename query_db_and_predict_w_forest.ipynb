{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e83e8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful article about OHLC data aggregation:\n",
    "# applicable to websocket streams of tick by tick data\n",
    "# https://blog.quantinsti.com/tick-tick-ohlc-data-pandas-tutorial/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a08f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter did not want to load already installed talib library \n",
    "# so had to reinstall it via anaconda as well \n",
    "#!conda install -c conda-forge ta-lib\n",
    "import talib as ta\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93a8d087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# custom function imports\n",
    "from functions_ml import *\n",
    "from functions_gen import *\n",
    "\n",
    "# custom indicators moved to modules\n",
    "from functions_superjump import *\n",
    "from functions_HHLL import *\n",
    "from functions_HHLL_conf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml model specific imports\n",
    "from functions_forest import *       # Random Forest classifier\n",
    "#from functions_nn import *          # Neural Net classifier, not needed when using forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32fdaf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqlite database structure is following:\n",
    "#\n",
    "#sqlite> .header on\n",
    "#sqlite> .mode column\n",
    "#sqlite> select * from alpaca_websocket_stream_data LIMIT 10;\n",
    "#timestamp                            symbol  price   size  exchange  conditions  tape  id   \n",
    "#-----------------------------------  ------  ------  ----  --------  ----------  ----  -----\n",
    "#2022-07-19 15:49:25.477387108-04:00  AAPL    150.8   100   V         ['@']       C     10807\n",
    "#32022-07-19 15:49:27.252579851-04:00  AAPL    150.81  3     V         ['@', 'I']  C     10808\n",
    "#2022-07-19 15:49:27.252579851-04:00  AAPL    150.81  100   V         ['@']       C     10809\n",
    "#2022-07-19 15:49:27.666163652-04:00  AAPL    150.81  100   V         ['@']       C     10810\n",
    "#2022-07-19 15:49:27.666164795-04:00  AAPL    150.81  200   V         ['@']       C     10811\n",
    "#2022-07-19 15:49:29.248316808-04:00  AAPL    150.79  100   V         ['@']       C     10812\n",
    "#2022-07-19 15:49:32.963910211-04:00  AAPL    150.78  35    V         ['@', 'I']  C     10813\n",
    "#2022-07-19 15:49:36.611092454-04:00  AAPL    150.77  2     V         ['@', 'I']  C     10814\n",
    "#2022-07-19 15:49:36.612940345-04:00  AAPL    150.77  100   V         ['@']       C     10815\n",
    "#2022-07-19 15:49:37.083678369-04:00  AAPL    150.76  100   V         ['@']       C     10816\n",
    "#sqlite> \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c98bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd0e6607",
   "metadata": {},
   "source": [
    "# Exploratory data wrangling\n",
    "optionally uncomment the code to get insights to individual steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52d55404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to sqlite database and get all data where symbol is AAPL\n",
    "# symbol is external variable\n",
    "# pandas to onnect to database and aggregate price data to 1 minute granularity in pandas\n",
    "\n",
    "#symbol='AAPL'\n",
    "#\n",
    "#conn = sqlite3.connect(\"alpaca_websocket_stream_data.db\")\n",
    "#c = conn.cursor()\n",
    "#c.execute(\"SELECT * FROM alpaca_websocket_stream_data WHERE symbol = ?\", (symbol,))\n",
    "#data = c.fetchall()\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "523ebbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa831a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b110aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ONE DAY BACK\n",
    "\n",
    "# connect to sqlite database and get all data where symbol is AAPL\n",
    "# timestamp is from 24 hours ago to now\n",
    "#conn = sqlite3.connect(\"alpaca_websocket_stream_data.db\")\n",
    "#c = conn.cursor()\n",
    "#c.execute(\"SELECT * FROM alpaca_websocket_stream_data WHERE symbol = 'AAPL' AND timestamp BETWEEN datetime('now', '-1 month') AND datetime('now')\")\n",
    "#data = c.fetchall()\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc680fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194dea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6a5b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data to dataframe\n",
    "#df = pd.DataFrame(data, columns=[\"timestamp\", \"symbol\", \"price\", \"size\", \"exchange\", \"conditions\", \"tape\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fa99c08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0747b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cfcf543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"date\"] = df[\"timestamp\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b17ff698",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4441123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.set_index(\"timestamp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bface1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73187d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_resampled = df['price'].resample(\"1Min\").ohlc(_method='ohlc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1da707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a050d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.reset_index()\n",
    "#df = df.sort_values(by=[\"symbol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f747bd",
   "metadata": {},
   "source": [
    "# Making function flow\n",
    "one function for getting the data for specific ticker from the database\n",
    "another function to process the df into resampled df with 1 and 5 min granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0d7c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'AAPL'\n",
    "db_name = 'alpaca_websocket_stream_data.db'\n",
    "table_name= 'alpaca_websocket_stream_data'\n",
    "granularity = '1Min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2ad3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_data_from_db_days_back(symbol, db_name, table_name):\n",
    "    # load data n days back from db\n",
    "    # connect to sqlite database and get all data where symbol is AAPL for example\n",
    "    # timestamp is from 24 hours ago to now\n",
    "    # symbol, database name, table name are external variables\n",
    "    \n",
    "    conn = sqlite3.connect(db_name)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"SELECT * FROM  {table_name} WHERE symbol = ? AND timestamp BETWEEN datetime('now', '-7 days') AND datetime('now')\", (symbol,))\n",
    "    data = c.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73369eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  get_ticker_data_from_db_days_back(symbol, db_name, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14f31de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7164bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "907df2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_data_from_db(symbol, db_name, table_name):\n",
    "    # connect to sqlite database and get all data where symbol is AAPL for example\n",
    "    # symbol, database name, table name are external variables\n",
    "    \n",
    "    conn = sqlite3.connect(db_name)\n",
    "    c = conn.cursor()\n",
    "    #c.execute(\"SELECT * FROM ? WHERE symbol = ?\", (table_name, symbol,))\n",
    "    c.execute(f\"SELECT * FROM {table_name} WHERE symbol = ?\", (symbol,))\n",
    "    data = c.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9354be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data =  get_ticker_data_from_db(symbol, db_name, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2641e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ba7d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now we have data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141dc753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93e77a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(data, granularity='1Min'):\n",
    "    # takes incoming data, converst it to dataframe\n",
    "    # and resamples tick by tick 'price' column into new dataframe, returns resampled dataframe\n",
    "    # granularity can be 1Min, 5Min, other granularities are also possible\n",
    "    \n",
    "    # load data to dataframe\n",
    "    df = pd.DataFrame(data, columns=[\"timestamp\", \"symbol\", \"price\", \"size\", \"exchange\", \"conditions\", \"tape\", \"id\"])\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ns\")\n",
    "    df = df.set_index(\"timestamp\")\n",
    "    df_res = df['price'].resample(granularity).ohlc(_method='ohlc')\n",
    "\n",
    "    # the neural net and Random Forest models expect df with columns called\n",
    "    # 'Date','Open', 'High', 'Low', 'Close', 'Adj Close'\n",
    "    # so we need to slightly mod our resampled df\n",
    "    df_res.reset_index(inplace=True)\n",
    "    df_res.rename(columns={\"timestamp\": \"Date\", \"open\": \"Open\", \"high\": \"High\", \"low\": \"Low\", \"close\": \"Close\"}, inplace=True)\n",
    "    df_res[\"Adj Close\"] = df_res[\"Close\"]\n",
    "    \n",
    "    # data stream is not continuous, there are gaps between days, we need to remove the gaps\n",
    "    # by taking only rows wit values that are not NaN\n",
    "    # very important, otherwise indicators will compute wrong values\n",
    "    df_res = df_res[df_res['Close'].notna()]\n",
    "    \n",
    "    #df_res.head()    \n",
    "\n",
    "    return df_res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d37fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "914b2429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd20fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a436ca6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot reset_index inplace on a Series to create a DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_res \u001b[38;5;241m=\u001b[39m  \u001b[43mresample_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgranularity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgranularity\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36mresample_data\u001b[0;34m(data, granularity)\u001b[0m\n\u001b[1;32m     10\u001b[0m df_res \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mresample(granularity)\u001b[38;5;241m.\u001b[39mohlc(_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mohlc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# the neural net and Random Forest models expect df with columns called\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 'Date','Open', 'High', 'Low', 'Close', 'Adj Close'\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# so we need to slightly mod our resampled df\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mdf_res\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df_res\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m df_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdj Close\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/real_time_trading_ml/.env/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/real_time_trading_ml/.env/lib/python3.10/site-packages/pandas/core/series.py:1481\u001b[0m, in \u001b[0;36mSeries.reset_index\u001b[0;34m(self, level, drop, name, inplace)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(\n\u001b[1;32m   1478\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mcopy(), index\u001b[38;5;241m=\u001b[39mnew_index\n\u001b[1;32m   1479\u001b[0m         )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreset_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inplace:\n\u001b[0;32m-> 1481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot reset_index inplace on a Series to create a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1483\u001b[0m     )\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1486\u001b[0m         \u001b[38;5;66;03m# For backwards compatibility, keep columns as [0] instead of\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m         \u001b[38;5;66;03m#  [None] when self.name is None\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot reset_index inplace on a Series to create a DataFrame"
     ]
    }
   ],
   "source": [
    "df_res =  resample_data(data, granularity=granularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccaf98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2dceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7412f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7805a484",
   "metadata": {},
   "source": [
    "## Model training (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa3b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed so far, we can import pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6825be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but best to allow for training here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d946bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training stock data\n",
    "tickers = ['SPY', 'F', 'IBM', 'GE', 'AAPL', 'ADM'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequence(tickers, interval=\"1m\", model_name=\"./random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a20bcd",
   "metadata": {},
   "source": [
    "## Feature importance visualization \n",
    "(Random Forest only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe7a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classifier, no need to initialize the loaded_rf\n",
    "clf = joblib.load(\"./random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_list = ['aboveSAR','aboveUpperBB','belowLowerBB','RSI','oversoldRSI','overboughtRSI',\n",
    "                   'aboveEMA5','aboveEMA10','aboveEMA15','aboveEMA20','aboveEMA30','aboveEMA40','aboveEMA50',\n",
    "                   'aboveEMA60','aboveEMA70','aboveEMA80','aboveEMA90',\n",
    "                   'aboveEMA100','aboveEMA200',\n",
    "                   'LongSig','ShortSig','WLongSig','WShortSig',\n",
    "                   'HH','LL','HL','LH',\n",
    "                   'trend_conf'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34053d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forest_feature_importances(clf, predictors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e21e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97fac6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fff5e0f",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "- now we have dataframe and can compute whatever indicators we want\n",
    "- and then connect it to our predictive model and even visualize in streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classifier, no need to initialize the loaded_rf\n",
    "clf = joblib.load(\"./random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd75fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe37572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = compute_technical_indicators(df_res)\n",
    "df_res = compute_features(df_res)\n",
    "df_res =define_target_condition(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf516af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd8906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- plot whole dataframe ---\n",
    "#df_res[['Open','High','Low','Close', 'EMA20']].plot()\n",
    "df_res[['Open','High','Low','Close']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497eb9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- plot tail of the dataframe ---\n",
    "df_res[['Open','High','Low','Close']].iloc[-20:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ca00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need only smaller slice\n",
    "df_res_cut = df_res.iloc[-202:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d5c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba7f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#new_df = predict_timeseries(new_df, clf)\n",
    "predict_timeseries(df_res_cut, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d97f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# when there is short history, the starts of EMAs will be anchored to zero, that will skew the graph\n",
    "# best to run when you have more than 1000 datapoints (in this case minutes) \n",
    "plot_stock_prediction(df_res_cut, symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da23f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb19784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3d766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d527e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add new column to better visualize Long only trades\n",
    "#df_res_cut['Long'] = df_res_cut['Buy'] * df_res_cut['Adj Close'] \n",
    "#df_res_cut['Long'].replace(0, np.nan, inplace=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_res_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dfdf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71d369f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d47422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes longer to compute, but predicts 200 datapoints to validate visually\n",
    "\n",
    "def predict_timeseries(df, clf):\n",
    "\n",
    "    # making sure we have good dimensions\n",
    "    # column will be rewritten later\n",
    "    df[\"Buy\"] = np.nan\n",
    "\n",
    "    print(\"df length: \", len(df))\n",
    "\n",
    "    # for i in range(len(df)):\n",
    "    #    print('above sar: ', df[\"aboveSAR\"][i])\n",
    "\n",
    "    # iterate over last 20 rows in a dataframe\n",
    "    # use df.iterrows() to iterate over rows\n",
    "    #for i, row in df.tail(\n",
    "    #    20\n",
    "    #).iterrows():  # predict for small subset of data, otherwise it takes too long\n",
    "\n",
    "    for i, row in df.iterrows():    # predict for each row\n",
    "\n",
    "        X_cls_valid = [\n",
    "            [\n",
    "                df[\"aboveSAR\"][i],\n",
    "                df[\"aboveUpperBB\"][i],\n",
    "                df[\"belowLowerBB\"][i],\n",
    "                df[\"RSI\"][i],\n",
    "                df[\"oversoldRSI\"][i],\n",
    "                df[\"overboughtRSI\"][i],\n",
    "                df[\"aboveEMA5\"][i],\n",
    "                df[\"aboveEMA10\"][i],\n",
    "                df[\"aboveEMA15\"][i],\n",
    "                df[\"aboveEMA20\"][i],\n",
    "                df[\"aboveEMA30\"][i],\n",
    "                df[\"aboveEMA40\"][i],\n",
    "                df[\"aboveEMA50\"][i],\n",
    "                df[\"aboveEMA60\"][i],\n",
    "                df[\"aboveEMA70\"][i],\n",
    "                df[\"aboveEMA80\"][i],\n",
    "                df[\"aboveEMA90\"][i],\n",
    "                df[\"aboveEMA100\"][i],\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        y_cls_pred_valid = clf.predict(X_cls_valid)\n",
    "        df[\"Buy\"][i] = y_cls_pred_valid[0].copy()\n",
    "\n",
    "        print(\"step: \", i, \"predicted class: \", df[\"Buy\"][i])\n",
    "\n",
    "\n",
    "    # add new column to better visualize Long only trades\n",
    "    # graphs will look better, since no anchoring to zero for short trades\n",
    "    df['Long'] = df['Buy'] * df['Adj Close'] \n",
    "    df['Long'].replace(0, np.nan, inplace=True) \n",
    "\n",
    "    print(df.tail())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ec4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inter trading day gaps in matplotlib issue proposed solution:\n",
    "# https://stackoverflow.com/questions/39231410/ignoring-time-gaps-larger-than-x-mins-matplotlib-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81fecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index for better plotting without gaps with zooming function\n",
    "df_res_cut.reset_index(inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33493795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock_prediction_zoom(df, ticker):\n",
    "    # --- plot only Long trades and zoom in on last data ---\n",
    "    \n",
    "    # plot  values and significant levels\n",
    "    #df.reset_index(inplace=True)    \n",
    "    \n",
    "    # zoom in\n",
    "    df = df.iloc[-200:]   # use eg. 50 for zooming in\n",
    "    \n",
    "    plt.figure(figsize=(20, 7))\n",
    "    plt.title(\"Predictive model \" + str(ticker))\n",
    "    plt.plot(df.index, df[\"Adj Close\"], label=\"High\", alpha=0.4)\n",
    "\n",
    "    plt.plot(df.index, df[\"EMA10\"], label=\"EMA10\", alpha=0.2)\n",
    "    plt.plot(df.index, df[\"EMA20\"], label=\"EMA20\", alpha=0.2)\n",
    "    plt.plot(df.index, df[\"EMA30\"], label=\"EMA30\", alpha=0.2)\n",
    "    plt.plot(df.index, df[\"EMA40\"], label=\"EMA40\", alpha=0.2)\n",
    "    plt.plot(df.index, df[\"EMA50\"], label=\"EMA50\", alpha=0.2)\n",
    "    #plt.plot(df.index, df[\"EMA100\"], label=\"EMA100\", alpha=0.2)\n",
    "    #plt.plot(df.index, df[\"EMA150\"], label=\"EMA150\", alpha=0.79)\n",
    "    #plt.plot(df.index, df[\"EMA200\"], label=\"EMA200\", alpha=0.99)\n",
    "\n",
    "    # this dataobject plotting gives intraday gaps since data from non trading time is not there\n",
    "    #plt.scatter(\n",
    "    #    df[\"Date\"],\n",
    "    #    #df[\"Buy\"] * df[\"Adj Close\"],\n",
    "    #    df['Long'],\n",
    "    #    label=\"Buy\",\n",
    "    #    marker=\"^\",\n",
    "    #    color=\"magenta\",\n",
    "    #    alpha=0.55,\n",
    "    #)\n",
    "    \n",
    "    # workaround with plotting over index\n",
    "\n",
    "    plt.scatter(\n",
    "        df.index,\n",
    "        #df[\"Buy\"] * df[\"Adj Close\"],\n",
    "        df['Long'],\n",
    "        label=\"Buy\",\n",
    "        marker=\"^\",\n",
    "        color=\"magenta\",\n",
    "        alpha=0.55,\n",
    "    )    \n",
    "    \n",
    "    # avoid intraday gaps by overlaying timestamp values over index ticks\n",
    "    plt.xticks(df.index, df['Date'], rotation='vertical')\n",
    "    \n",
    "    # make sure the x date ticks are not overlapping\n",
    "    plt.locator_params(axis='x', nbins=15)\n",
    "    \n",
    "    #plt.xticks(x, labels, rotation='vertical')\n",
    "    # Pad margins so that markers don't get clipped by the axes \n",
    "    #plt.margins(0.2)\n",
    "    # Tweak spacing to prevent clipping of tick-labels\n",
    "    #plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stock_prediction_zoom(df_res_cut, symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d460e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3396e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb987e7f",
   "metadata": {},
   "source": [
    "# Daemonize the script to run every minute\n",
    "but running script every minute by cron should be more reliable, also prevents time drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3304e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- UNCOMMENT TO RUN CONTINUOUSLY ---\n",
    "\n",
    "#while True:\n",
    "#    \n",
    "#    #data =  get_ticker_data_from_db(symbol, db_name, table_name)\n",
    "#    data =  get_ticker_data_from_db_days_back(symbol, db_name, table_name)\n",
    "#    df_res =  resample_data(data, granularity=granularity)\n",
    "#    \n",
    "#    df_res = compute_technical_indicators(df_res)\n",
    "#    df_res = compute_features(df_res)\n",
    "#    df_res =define_target_condition(df_res)\n",
    "#\n",
    "#    # streamline for pred and viz\n",
    "#    df_res_cut = df_res.iloc[-202:].copy()\n",
    "#    predict_timeseries(df_res_cut, clf)\n",
    "#    plot_stock_prediction(df_res_cut, symbol)\n",
    "#\n",
    "#    time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1071b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
